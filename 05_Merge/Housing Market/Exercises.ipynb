{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Housing Market"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction:\n",
    "\n",
    "This time we will create our own dataset with fictional numbers to describe a house market. As we are going to create random data don't try to reason of the numbers.\n",
    "\n",
    "### Step 1. Import the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import IntegerType\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/10/11 00:35:10 WARN Utils: Your hostname, xkeyscore resolves to a loopback address: 127.0.1.1; using 192.168.1.11 instead (on interface wlp0s20f3)\n",
      "22/10/11 00:35:10 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/10/11 00:35:11 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "22/10/11 00:35:11 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "22/10/11 00:35:11 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.\n",
      "22/10/11 00:35:11 WARN Utils: Service 'SparkUI' could not bind on port 4042. Attempting port 4043.\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder.master(\"local[1]\").appName(\"cars\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2. Create 3 differents Series, each of length 100, as follows: \n",
    "1. The first a random number from 1 to 4 \n",
    "2. The second a random number from 1 to 3\n",
    "3. The third a random number from 10,000 to 30,000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "first, second, third = [], [], []\n",
    "for i in range(0,100):\n",
    "    first.append(np.random.randint(1,4))\n",
    "    second.append(np.random.randint(1,3))\n",
    "    third.append(np.random.randint(10000,30000))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "series1 = sc.parallelize(first)\n",
    "series2 = sc.parallelize(second)\n",
    "series3 = sc.parallelize(third)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3. Let's create a DataFrame by joinning the Series by column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "df1 = spark.createDataFrame(series1,schema=\"int\")\n",
    "df2 = spark.createDataFrame(series2, schema=\"int\")\n",
    "df3 = spark.createDataFrame(series3, schema=\"int\")\n",
    "\n",
    "df = df1.join(df2).join(df3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+-----+\n",
      "|value|value|value|\n",
      "+-----+-----+-----+\n",
      "|    1|    2|17497|\n",
      "|    1|    2|24102|\n",
      "|    1|    2|17818|\n",
      "|    1|    2|15618|\n",
      "|    1|    2|19320|\n",
      "|    1|    2|10082|\n",
      "|    1|    2|18230|\n",
      "|    1|    2|16461|\n",
      "|    1|    2|18899|\n",
      "|    1|    2|29400|\n",
      "|    1|    2|29391|\n",
      "|    1|    2|25341|\n",
      "|    1|    2|14661|\n",
      "|    1|    2|13050|\n",
      "|    1|    2|10824|\n",
      "|    1|    2|27607|\n",
      "|    1|    2|13167|\n",
      "|    1|    2|12427|\n",
      "|    1|    2|12173|\n",
      "|    1|    2|20568|\n",
      "+-----+-----+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4. Change the name of the columns to bedrs, bathrs, price_sqr_meter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "new_columns=[\"bedrs\", \"bathrs\", \"price_sqr_meter\"]\n",
    "df = df.toDF(*new_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+---------------+\n",
      "|bedrs|bathrs|price_sqr_meter|\n",
      "+-----+------+---------------+\n",
      "|    1|     2|          17497|\n",
      "|    1|     2|          24102|\n",
      "|    1|     2|          17818|\n",
      "|    1|     2|          15618|\n",
      "|    1|     2|          19320|\n",
      "|    1|     2|          10082|\n",
      "|    1|     2|          18230|\n",
      "|    1|     2|          16461|\n",
      "|    1|     2|          18899|\n",
      "|    1|     2|          29400|\n",
      "|    1|     2|          29391|\n",
      "|    1|     2|          25341|\n",
      "|    1|     2|          14661|\n",
      "|    1|     2|          13050|\n",
      "|    1|     2|          10824|\n",
      "|    1|     2|          27607|\n",
      "|    1|     2|          13167|\n",
      "|    1|     2|          12427|\n",
      "|    1|     2|          12173|\n",
      "|    1|     2|          20568|\n",
      "+-----+------+---------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5. Create a one column DataFrame with the values of the 3 Series and assign it to 'bigcolumn'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n",
      "|bigcolumn|\n",
      "+---------+\n",
      "|    17497|\n",
      "|    24102|\n",
      "|    17818|\n",
      "|    15618|\n",
      "|    19320|\n",
      "|    10082|\n",
      "|    18230|\n",
      "|    16461|\n",
      "|    18899|\n",
      "|    29400|\n",
      "|    29391|\n",
      "|    25341|\n",
      "|    14661|\n",
      "|    13050|\n",
      "|    10824|\n",
      "|    27607|\n",
      "|    13167|\n",
      "|    12427|\n",
      "|    12173|\n",
      "|    20568|\n",
      "+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "new_df = df.select(F.col(\"price_sqr_meter\").alias(\"bigcolumn\"))\n",
    "new_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000000"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6. Oops, it seems it is going only until index 99. Is it true?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# No"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 7. Reindex the DataFrame so it goes from 0 to 299"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
