{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# US - Baby Names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction:\n",
    "\n",
    "We are going to use a subset of [US Baby Names](https://www.kaggle.com/kaggle/us-baby-names) from Kaggle.  \n",
    "In the file it will be names from 2004 until 2014\n",
    "\n",
    "\n",
    "### Step 1. Import the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/10/11 01:05:27 WARN Utils: Your hostname, xkeyscore resolves to a loopback address: 127.0.1.1; using 192.168.1.11 instead (on interface wlp0s20f3)\n",
      "22/10/11 01:05:27 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/10/11 01:05:27 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "22/10/11 01:05:28 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "22/10/11 01:05:28 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.\n",
      "22/10/11 01:05:28 WARN Utils: Service 'SparkUI' could not bind on port 4042. Attempting port 4043.\n",
      "22/10/11 01:05:28 WARN Utils: Service 'SparkUI' could not bind on port 4043. Attempting port 4044.\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder.master(\"local[1]\").appName(\"cars\").getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2. Import the dataset from this [address](https://raw.githubusercontent.com/guipsamora/pandas_exercises/master/06_Stats/US_Baby_Names/US_Baby_Names_right.csv). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3. Assign it to a variable called baby_names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 1:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/10/11 01:06:42 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , Id, Name, Year, Gender, State, Count\n",
      " Schema: _c0, Id, Name, Year, Gender, State, Count\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/chiragsehra/Documents/pyspark_exercises/06_Stats/US_Baby_Names/US_Baby_Names_right.csv\n",
      "+-----+-----+-------+----+------+-----+-----+\n",
      "|  _c0|   Id|   Name|Year|Gender|State|Count|\n",
      "+-----+-----+-------+----+------+-----+-----+\n",
      "|11349|11350|   Emma|2004|     F|   AK|   62|\n",
      "|11350|11351|Madison|2004|     F|   AK|   48|\n",
      "|11351|11352| Hannah|2004|     F|   AK|   46|\n",
      "|11352|11353|  Grace|2004|     F|   AK|   44|\n",
      "|11353|11354|  Emily|2004|     F|   AK|   41|\n",
      "+-----+-----+-------+----+------+-----+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "baby_names = spark.read.csv(\"US_Baby_Names_right.csv\", inferSchema=True, header=True)\n",
    "baby_names.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4. See the first 10 entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/10/11 01:07:00 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , Id, Name, Year, Gender, State, Count\n",
      " Schema: _c0, Id, Name, Year, Gender, State, Count\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/chiragsehra/Documents/pyspark_exercises/06_Stats/US_Baby_Names/US_Baby_Names_right.csv\n",
      "+-----+-----+--------+----+------+-----+-----+\n",
      "|  _c0|   Id|    Name|Year|Gender|State|Count|\n",
      "+-----+-----+--------+----+------+-----+-----+\n",
      "|11349|11350|    Emma|2004|     F|   AK|   62|\n",
      "|11350|11351| Madison|2004|     F|   AK|   48|\n",
      "|11351|11352|  Hannah|2004|     F|   AK|   46|\n",
      "|11352|11353|   Grace|2004|     F|   AK|   44|\n",
      "|11353|11354|   Emily|2004|     F|   AK|   41|\n",
      "|11354|11355| Abigail|2004|     F|   AK|   37|\n",
      "|11355|11356|  Olivia|2004|     F|   AK|   33|\n",
      "|11356|11357|Isabella|2004|     F|   AK|   30|\n",
      "|11357|11358|  Alyssa|2004|     F|   AK|   29|\n",
      "|11358|11359|  Sophia|2004|     F|   AK|   28|\n",
      "+-----+-----+--------+----+------+-----+-----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "baby_names.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5. Delete the column 'Unnamed: 0' and 'Id'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----+------+-----+-----+\n",
      "|   Name|Year|Gender|State|Count|\n",
      "+-------+----+------+-----+-----+\n",
      "|   Emma|2004|     F|   AK|   62|\n",
      "|Madison|2004|     F|   AK|   48|\n",
      "| Hannah|2004|     F|   AK|   46|\n",
      "|  Grace|2004|     F|   AK|   44|\n",
      "|  Emily|2004|     F|   AK|   41|\n",
      "+-------+----+------+-----+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "baby_names = baby_names.drop(F.col(\"_c0\")).drop(F.col(\"Id\"))\n",
    "baby_names.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6. Is there more male or female names in the dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 12:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------+\n",
      "|Gender| count|\n",
      "+------+------+\n",
      "|     F|558846|\n",
      "|     M|457549|\n",
      "+------+------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "baby_names.select(F.col(\"Gender\")).groupby(\"Gender\").count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 7. Group the dataset by name and assign to names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----+\n",
      "|    name|count|\n",
      "+--------+-----+\n",
      "|   Kiana|  341|\n",
      "|  Alayna|  469|\n",
      "|   Ember|  262|\n",
      "|   Tyler|  770|\n",
      "|  Maddox|  537|\n",
      "|  Kellen|  398|\n",
      "|  Heaven|  403|\n",
      "|Julianne|  257|\n",
      "| Susanna|  151|\n",
      "|  Kenlee|   76|\n",
      "|    Kloe|  153|\n",
      "|   Anyah|   68|\n",
      "|   Tegan|  322|\n",
      "| Jazzlyn|   96|\n",
      "|Brileigh|   20|\n",
      "|Analeigh|   57|\n",
      "|Kamarion|  118|\n",
      "|   Aryan|  212|\n",
      "| Galilea|  119|\n",
      "|    Faye|  126|\n",
      "+--------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "names = baby_names.select(\"name\").groupby(\"name\").count()\n",
    "names.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 8. How many different names exist in the dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "17632"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 9. What is the name with most occurrences?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 38:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+\n",
      "|   name|count|\n",
      "+-------+-----+\n",
      "|  Riley| 1112|\n",
      "|  Avery| 1080|\n",
      "| Jordan| 1073|\n",
      "| Peyton| 1064|\n",
      "| Hayden| 1049|\n",
      "| Taylor| 1033|\n",
      "| Jayden| 1031|\n",
      "| Alexis|  984|\n",
      "| Payton|  971|\n",
      "|  Angel|  962|\n",
      "| Dakota|  962|\n",
      "|  Logan|  957|\n",
      "| Parker|  947|\n",
      "| Morgan|  945|\n",
      "|Cameron|  944|\n",
      "|   Ryan|  901|\n",
      "|  Dylan|  895|\n",
      "| Skyler|  895|\n",
      "|  Reese|  880|\n",
      "|  Quinn|  873|\n",
      "+-------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "names.orderBy(F.desc(\"count\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 10. How many different names have the least occurrences?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_count = names.select(F.min(F.col(\"count\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "ename": "AnalysisException",
     "evalue": "\nAggregate/Window/Generate expressions are not valid in where clause of the query.\nExpression in where clause: [(count = min(count))]\nInvalid expressions: [min(count)];\nFilter (count#355L = min(count#355L))\n+- Project [name#19, count#355L]\n   +- Aggregate [name#19], [name#19, count(1) AS count#355L]\n      +- Project [name#19]\n         +- Project [Name#19, Year#20, Gender#21, State#22, Count#23]\n            +- Project [Id#18, Name#19, Year#20, Gender#21, State#22, Count#23]\n               +- Relation [_c0#17,Id#18,Name#19,Year#20,Gender#21,State#22,Count#23] csv\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [49]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mnames\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcol\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mname\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcol\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcount\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfilter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcol\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcount\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcol\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcount\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/pyspark_exercises/venv/lib/python3.8/site-packages/pyspark/sql/dataframe.py:2079\u001b[0m, in \u001b[0;36mDataFrame.filter\u001b[0;34m(self, condition)\u001b[0m\n\u001b[1;32m   2077\u001b[0m     jdf \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jdf\u001b[38;5;241m.\u001b[39mfilter(condition)\n\u001b[1;32m   2078\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(condition, Column):\n\u001b[0;32m-> 2079\u001b[0m     jdf \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfilter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcondition\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2080\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2081\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcondition should be string or Column\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Documents/pyspark_exercises/venv/lib/python3.8/site-packages/py4j/java_gateway.py:1321\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1315\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1316\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1317\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1318\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[1;32m   1320\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[0;32m-> 1321\u001b[0m return_value \u001b[38;5;241m=\u001b[39m \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1322\u001b[0m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1324\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[1;32m   1325\u001b[0m     temp_arg\u001b[38;5;241m.\u001b[39m_detach()\n",
      "File \u001b[0;32m~/Documents/pyspark_exercises/venv/lib/python3.8/site-packages/pyspark/sql/utils.py:196\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    192\u001b[0m converted \u001b[38;5;241m=\u001b[39m convert_exception(e\u001b[38;5;241m.\u001b[39mjava_exception)\n\u001b[1;32m    193\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(converted, UnknownException):\n\u001b[1;32m    194\u001b[0m     \u001b[38;5;66;03m# Hide where the exception came from that shows a non-Pythonic\u001b[39;00m\n\u001b[1;32m    195\u001b[0m     \u001b[38;5;66;03m# JVM exception message.\u001b[39;00m\n\u001b[0;32m--> 196\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m converted \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m    197\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    198\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[0;31mAnalysisException\u001b[0m: \nAggregate/Window/Generate expressions are not valid in where clause of the query.\nExpression in where clause: [(count = min(count))]\nInvalid expressions: [min(count)];\nFilter (count#355L = min(count#355L))\n+- Project [name#19, count#355L]\n   +- Aggregate [name#19], [name#19, count(1) AS count#355L]\n      +- Project [name#19]\n         +- Project [Name#19, Year#20, Gender#21, State#22, Count#23]\n            +- Project [Id#18, Name#19, Year#20, Gender#21, State#22, Count#23]\n               +- Relation [_c0#17,Id#18,Name#19,Year#20,Gender#21,State#22,Count#23] csv\n"
     ]
    }
   ],
   "source": [
    "names.select(F.col(\"name\"), F.col(\"count\")).filter(F.col(\"count\") == F.min(F.col(\"count\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 11. What is the median name occurrence?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 12. What is the standard deviation of names?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 13. Get a summary with the mean, min, max, std and quartiles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 92:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------+------------------+-------+-------+-----------------+\n",
      "|summary|    Name|              Year| Gender|  State|            Count|\n",
      "+-------+--------+------------------+-------+-------+-----------------+\n",
      "|  count| 1016395|           1016395|1016395|1016395|          1016395|\n",
      "|   mean|Infinity|2009.0531899507573|   null|   null|34.85012421351935|\n",
      "| stddev|    null|3.1382928281815494|   null|   null| 97.3973464861767|\n",
      "|    min|   Aaban|              2004|      F|     AK|                5|\n",
      "|    max|  Zyriah|              2014|      M|     WY|             4167|\n",
      "+-------+--------+------------------+-------+-------+-----------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "baby_names.describe().show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
